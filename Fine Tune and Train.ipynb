{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version                                               data\n",
       "0    v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
       "1    v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2    v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3    v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
       "4    v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQuAD = pd.read_json(\"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\")\n",
    "SQuAD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del  SQuAD['version']\n",
    "cols = ['text', 'question', 'answer']\n",
    "\n",
    "comp_list = []\n",
    "for index, row in SQuAD.iterrows():\n",
    "    for i in range(len(row['data']['paragraphs'])):\n",
    "        for j in (row['data']['paragraphs'][i]['qas']):\n",
    "            temp_list = []\n",
    "            temp_list.append(row[\"data\"][\"paragraphs\"][i][\"context\"])\n",
    "            temp_list.append(j[\"question\"])\n",
    "            if j[\"answers\"]:\n",
    "                temp_list.append(j[\"answers\"][0][\"text\"])\n",
    "            else:\n",
    "                temp_list.append(\"\")\n",
    "        comp_list.append(temp_list)\n",
    "new_df = pd.DataFrame(comp_list,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What was the name of Beyoncé's first solo album?</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>What is the name of Beyoncé's alter-ego?</td>\n",
       "      <td>Sasha Fierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "      <td>What magazine named Beyoncé as the most powerf...</td>\n",
       "      <td>Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "      <td>Beyoncé was raised in what religion?</td>\n",
       "      <td>Methodist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "      <td>What choir did Beyoncé sing in for two years?</td>\n",
       "      <td>St. John's United Methodist Church</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Following the disbandment of Destiny's Child i...   \n",
       "2  A self-described \"modern-day feminist\", Beyonc...   \n",
       "3  Beyoncé Giselle Knowles was born in Houston, T...   \n",
       "4  Beyoncé attended St. Mary's Elementary School ...   \n",
       "\n",
       "                                            question  \\\n",
       "0   What was the name of Beyoncé's first solo album?   \n",
       "1           What is the name of Beyoncé's alter-ego?   \n",
       "2  What magazine named Beyoncé as the most powerf...   \n",
       "3               Beyoncé was raised in what religion?   \n",
       "4      What choir did Beyoncé sing in for two years?   \n",
       "\n",
       "                               answer  \n",
       "0                 Dangerously in Love  \n",
       "1                        Sasha Fierce  \n",
       "2                              Forbes  \n",
       "3                           Methodist  \n",
       "4  St. John's United Methodist Church  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.to_csv(\"SQuAD_data.csv\", index=False)\n",
    "data = pd.read_csv(\"SQuAD_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 443/443 [00:00<00:00, 69.4kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.34G/1.34G [00:23<00:00, 57.7MB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 714kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 10.4kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0, len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!mv SQuAD_data.csv data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What type of wood can hold four times as much of a load when dried?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drying produces a decided increase in the strength of wood, particularly in small specimens. An extreme example is the case of a completely dry spruce block 5 cm in section, which will sustain a permanent load four times as great as a green (undried) block of the same size will.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 76 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "what        2054\n",
      "type        2828\n",
      "of          1997\n",
      "wood        3536\n",
      "can         2064\n",
      "hold        2907\n",
      "four        2176\n",
      "times       2335\n",
      "as          2004\n",
      "much        2172\n",
      "of          1997\n",
      "a           1037\n",
      "load        7170\n",
      "when        2043\n",
      "dried       9550\n",
      "?           1029\n",
      "[SEP]        102\n",
      "drying     17462\n",
      "produces    7137\n",
      "a           1037\n",
      "decided     2787\n",
      "increase    3623\n",
      "in          1999\n",
      "the         1996\n",
      "strength    3997\n",
      "of          1997\n",
      "wood        3536\n",
      ",           1010\n",
      "particularly    3391\n",
      "in          1999\n",
      "small       2235\n",
      "specimens    9908\n",
      ".           1012\n",
      "an          2019\n",
      "extreme     6034\n",
      "example     2742\n",
      "is          2003\n",
      "the         1996\n",
      "case        2553\n",
      "of          1997\n",
      "a           1037\n",
      "completely    3294\n",
      "dry         4318\n",
      "spruce     19893\n",
      "block       3796\n",
      "5           1019\n",
      "cm          4642\n",
      "in          1999\n",
      "section     2930\n",
      ",           1010\n",
      "which       2029\n",
      "will        2097\n",
      "sustain    15770\n",
      "a           1037\n",
      "permanent    4568\n",
      "load        7170\n",
      "four        2176\n",
      "times       2335\n",
      "as          2004\n",
      "great       2307\n",
      "as          2004\n",
      "a           1037\n",
      "green       2665\n",
      "(           1006\n",
      "und         6151\n",
      "##ried     11998\n",
      ")           1007\n",
      "block       3796\n",
      "of          1997\n",
      "the         1996\n",
      "same        2168\n",
      "size        2946\n",
      "will        2097\n",
      ".           1012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print(\"{:8}{:8}\".format(token, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "58\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(sep_idx)\n",
    "\n",
    "# number of tokens in segment A - question\n",
    "num_seg_a = sep_idx + 1\n",
    "print(num_seg_a)\n",
    "\n",
    "#number of tokens in segment B - text\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(num_seg_b)\n",
    "\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "print(segment_ids)\n",
    "\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.5570, -3.6428, -7.7892, -7.3022, -7.3378, -8.5929, -8.7354, -9.1374,\n",
      "         -9.4038, -9.1775, -9.1694, -8.8319, -8.7167, -9.0042, -8.4514, -7.9351,\n",
      "         -9.3174, -6.5569, -2.8911, -7.0641, -6.9028, -6.0249, -5.9022, -7.9937,\n",
      "         -6.0126, -5.4645, -7.3554, -3.3017, -7.5972, -6.2685, -6.5429, -4.4986,\n",
      "         -5.5158, -6.5569, -3.5121, -5.0184, -4.9290, -5.7100, -3.9372, -4.7136,\n",
      "         -3.2312,  4.5708,  3.3033,  2.7333,  8.1562,  1.0806, -2.0258, -4.9256,\n",
      "         -5.5844, -3.1432, -5.1337, -4.0815, -5.0982, -5.6637, -6.1958, -6.1446,\n",
      "         -5.5061, -3.2329, -6.0126, -7.2608, -6.5485, -6.3367, -0.3333,  1.1320,\n",
      "         -4.6226, -2.1368, -6.4142, -5.7904, -3.1184, -6.5893, -6.2802, -6.0601,\n",
      "         -4.3446, -6.4494, -7.3229, -6.5571]], grad_fn=<CloneBackward0>) tensor([[-1.4395, -1.9131, -5.6148, -4.9678, -6.0605, -7.6445, -7.5396, -7.1709,\n",
      "         -7.2522, -7.6118, -7.5136, -7.4072, -7.6763, -6.6284, -8.0881, -6.2145,\n",
      "         -6.6987, -1.4394, -2.4799, -6.5669, -7.4114, -6.9743, -6.5958, -7.4229,\n",
      "         -6.4464, -4.6187, -5.8286, -1.6180, -4.1204, -6.7068, -7.0660, -4.9188,\n",
      "         -2.1000, -1.4393, -6.8823, -6.4606, -5.3535, -7.2919, -7.2373, -5.9142,\n",
      "         -5.7115, -2.0195, -3.3241,  2.2659,  8.8920,  7.2521,  0.2947,  2.1675,\n",
      "         -0.3701,  5.1837,  2.0455, -3.9100, -5.7673, -4.6610, -5.9237, -5.5343,\n",
      "         -2.7792, -3.3281, -3.9039, -6.2487, -3.8160, -5.0660, -5.1357,  1.6135,\n",
      "         -5.1725, -4.3453, -1.4525,  0.3776,  1.4626, -5.3834, -5.9973, -3.0485,\n",
      "          2.3582,  0.2323,  0.0328, -1.4401]], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "print(output.start_logits, output.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44) tensor(44)\n",
      "Text: \n",
      "Drying produces a decided increase in the strength of wood, particularly in small specimens. an extreme example is the case of a completely dry spruce block 5 cm in section, which will sustain a permanent load four times as great as a green (undried) block of the same size will.\n",
      "\n",
      "Question: \n",
      "What type of wood can hold four times as much of a load when dried?\n",
      "\n",
      "Answer: \n",
      "Spruce\n"
     ]
    }
   ],
   "source": [
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "print (answer_start, answer_end)\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end + 1])\n",
    "else:\n",
    "    print(\"I am unable to answer your question? Please pardon\")\n",
    "\n",
    "print(\"Text: \\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion: \\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer: \\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spruce'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = tokens[answer_start]\n",
    "\n",
    "for i in range(answer_start+1, answer_end):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer +=tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "\n",
    "    # tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "\n",
    "    # string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # segment IDs\n",
    "    # first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # number of tokens in segment A - qustion \n",
    "    num_seg_a = sep_idx + 1\n",
    "\n",
    "    # number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # list of 0s and 1s\n",
    "    segment_ids =[0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # model output using input ids and sedment ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "\n",
    "    # reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer = \"\"\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "\n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question\"\n",
    "    \n",
    "    print(\"\\nAnswer: \\n{}\".format(answer.capitalize()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: \n",
      " dental clinic\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Shukran Dental Clinic is a leading provider of dental care services in Kenya, with locations in Eldoret and Nairobi. Our team of experienced and highly qualified dental professionals is dedicated to providing top-notch care to our patients in a warm, welcoming, and comfortable environment.\n",
    "\n",
    "We offer a wide range of dental services, including routine cleanings, fillings, extractions, crowns and bridges, orthodontics, and cosmetic procedures such as teeth whitening and veneers. Our state-of-the-art facilities and equipment allow us to provide efficient and effective treatments for all of our patients.\n",
    "\n",
    "The cost of our services varies depending on the specific procedure, but we strive to make our care as affordable as possible. Our staff will work with you to create a customized treatment plan that fits your budget, and we accept a variety of payment methods, including most major insurance plans.\n",
    "\n",
    "We accept patients with insurance coverage from the following insurance agencies:\n",
    "AAR Healthcare\n",
    "Britam Insurance\n",
    "Jubilee Insurance\n",
    "Sanlam Kenya\n",
    "CIC Insurance\n",
    "At Shukran Dental Clinic, our goal is to help our patients achieve and maintain optimal oral health. We believe in educating our patients about the importance of oral health and how they can take care of their teeth and gums at home. Contact us today to schedule an appointment and learn more about our dental services.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is the name of the clinic?\"\n",
    " \n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: \n",
      " town\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mwhile\u001b[39;00m flag:\n\u001b[1;32m     11\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDo you want to ask another question based on this text (Y/N)? \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mif\u001b[39;00m response[\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     13\u001b[0m         question \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mPlease enter your question: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m         flag \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "text = input(\"Please enter your text: \\n\")\n",
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    " \n",
    "while True:\n",
    "   question_answer(question, text)\n",
    "  \n",
    "   flag = True\n",
    "   flag_N = False\n",
    "  \n",
    "   while flag:\n",
    "       response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "       if response[0] == \"Y\":\n",
    "           question = input(\"\\nPlease enter your question: \\n\")\n",
    "           flag = False\n",
    "       elif response[0] == \"N\":\n",
    "           print(\"\\nBye!\")\n",
    "           flag = False\n",
    "           flag_N = True\n",
    "          \n",
    "   if flag_N == True:\n",
    "       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 10 2023, 15:23:34) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
