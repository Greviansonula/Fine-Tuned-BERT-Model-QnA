{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version                                               data\n",
       "0    v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
       "1    v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2    v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3    v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
       "4    v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQuAD = pd.read_json(\"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\")\n",
    "SQuAD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del  SQuAD['version']\n",
    "cols = ['text', 'question', 'answer']\n",
    "\n",
    "comp_list = []\n",
    "for index, row in SQuAD.iterrows():\n",
    "    for i in range(len(row['data']['paragraphs'])):\n",
    "        for j in (row['data']['paragraphs'][i]['qas']):\n",
    "            temp_list = []\n",
    "            temp_list.append(row[\"data\"][\"paragraphs\"][i][\"context\"])\n",
    "            temp_list.append(j[\"question\"])\n",
    "            if j[\"answers\"]:\n",
    "                temp_list.append(j[\"answers\"][0][\"text\"])\n",
    "            else:\n",
    "                temp_list.append(\"\")\n",
    "        comp_list.append(temp_list)\n",
    "new_df = pd.DataFrame(comp_list,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What was the name of Beyoncé's first solo album?</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>What is the name of Beyoncé's alter-ego?</td>\n",
       "      <td>Sasha Fierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "      <td>What magazine named Beyoncé as the most powerf...</td>\n",
       "      <td>Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "      <td>Beyoncé was raised in what religion?</td>\n",
       "      <td>Methodist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "      <td>What choir did Beyoncé sing in for two years?</td>\n",
       "      <td>St. John's United Methodist Church</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Following the disbandment of Destiny's Child i...   \n",
       "2  A self-described \"modern-day feminist\", Beyonc...   \n",
       "3  Beyoncé Giselle Knowles was born in Houston, T...   \n",
       "4  Beyoncé attended St. Mary's Elementary School ...   \n",
       "\n",
       "                                            question  \\\n",
       "0   What was the name of Beyoncé's first solo album?   \n",
       "1           What is the name of Beyoncé's alter-ego?   \n",
       "2  What magazine named Beyoncé as the most powerf...   \n",
       "3               Beyoncé was raised in what religion?   \n",
       "4      What choir did Beyoncé sing in for two years?   \n",
       "\n",
       "                               answer  \n",
       "0                 Dangerously in Love  \n",
       "1                        Sasha Fierce  \n",
       "2                              Forbes  \n",
       "3                           Methodist  \n",
       "4  St. John's United Methodist Church  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.to_csv(\"SQuAD_data.csv\", index=False)\n",
    "data = pd.read_csv(\"SQuAD_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 443/443 [00:00<00:00, 73.2kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.34G/1.34G [00:54<00:00, 24.8MB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 715kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 11.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0, len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!mv SQuAD_data.csv data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What type of instrument is the gamelan?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Electric instruments such as the electric guitar, the electric bass and the ondes Martenot appear occasionally in the classical music of the 20th and 21st centuries. Both classical and popular musicians have experimented in recent decades with electronic instruments such as the synthesizer, electric and digital techniques such as the use of sampled or computer-generated sounds, and instruments from other cultures such as the gamelan.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 88 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "what        2054\n",
      "type        2828\n",
      "of          1997\n",
      "instrument    6602\n",
      "is          2003\n",
      "the         1996\n",
      "game        2208\n",
      "##lan       5802\n",
      "?           1029\n",
      "[SEP]        102\n",
      "electric    3751\n",
      "instruments    5693\n",
      "such        2107\n",
      "as          2004\n",
      "the         1996\n",
      "electric    3751\n",
      "guitar      2858\n",
      ",           1010\n",
      "the         1996\n",
      "electric    3751\n",
      "bass        3321\n",
      "and         1998\n",
      "the         1996\n",
      "on          2006\n",
      "##des       6155\n",
      "mart       20481\n",
      "##eno      16515\n",
      "##t         2102\n",
      "appear      3711\n",
      "occasionally    5681\n",
      "in          1999\n",
      "the         1996\n",
      "classical    4556\n",
      "music       2189\n",
      "of          1997\n",
      "the         1996\n",
      "20th        3983\n",
      "and         1998\n",
      "21st        7398\n",
      "centuries    4693\n",
      ".           1012\n",
      "both        2119\n",
      "classical    4556\n",
      "and         1998\n",
      "popular     2759\n",
      "musicians    5389\n",
      "have        2031\n",
      "experimented   20918\n",
      "in          1999\n",
      "recent      3522\n",
      "decades     5109\n",
      "with        2007\n",
      "electronic    4816\n",
      "instruments    5693\n",
      "such        2107\n",
      "as          2004\n",
      "the         1996\n",
      "synthesizer   13564\n",
      ",           1010\n",
      "electric    3751\n",
      "and         1998\n",
      "digital     3617\n",
      "techniques    5461\n",
      "such        2107\n",
      "as          2004\n",
      "the         1996\n",
      "use         2224\n",
      "of          1997\n",
      "sampled    18925\n",
      "or          2030\n",
      "computer    3274\n",
      "-           1011\n",
      "generated    7013\n",
      "sounds      4165\n",
      ",           1010\n",
      "and         1998\n",
      "instruments    5693\n",
      "from        2013\n",
      "other       2060\n",
      "cultures    8578\n",
      "such        2107\n",
      "as          2004\n",
      "the         1996\n",
      "game        2208\n",
      "##lan       5802\n",
      ".           1012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print(\"{:8}{:8}\".format(token, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "77\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(sep_idx)\n",
    "\n",
    "# number of tokens in segment A - question\n",
    "num_seg_a = sep_idx + 1\n",
    "print(num_seg_a)\n",
    "\n",
    "#number of tokens in segment B - text\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(num_seg_b)\n",
    "\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "print(segment_ids)\n",
    "\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.3336,  -6.1691,  -8.1008,  -7.9677,  -8.8729,  -8.8805,  -8.5801,\n",
      "          -8.5550, -10.0506,  -9.7406,  -6.3336,   3.5561,  -3.8884,  -6.2494,\n",
      "          -6.7600,  -1.4761,   0.4539,  -3.7079,  -7.5307,  -2.8088,  -1.5048,\n",
      "          -3.9993,  -8.1322,  -3.3581,  -2.5602,  -6.2752,  -6.7095,  -7.3740,\n",
      "          -6.1552,  -5.7342,  -4.6686,  -7.0581,  -6.6008,  -3.5871,  -4.6654,\n",
      "          -8.2460,  -7.2821,  -6.7642,  -8.6052,  -6.8894,  -7.3000,  -7.0785,\n",
      "          -3.1269,  -2.9306,  -6.7148,  -1.3822,  -3.9576,  -5.5832,  -1.1957,\n",
      "          -6.5481,  -4.3572,  -5.8244,  -3.6150,   6.8833,  -2.8930,  -5.3856,\n",
      "          -5.2018,   0.7933,   1.3829,  -6.9217,  -1.4971,  -6.9072,  -0.9392,\n",
      "          -4.8722,  -7.5233,  -8.1356,  -5.9448,  -4.8833,  -7.6410,  -3.4765,\n",
      "          -7.8437,  -2.1763,  -7.5898,  -6.3052,  -5.2956,  -7.5174,  -5.6796,\n",
      "           0.8051,  -3.8917,  -3.4086,  -3.0935,  -6.3545,  -6.5248,  -1.0897,\n",
      "          -1.7854,  -6.1909,  -6.8574,  -6.3336]], grad_fn=<CloneBackward0>) tensor([[-1.4404, -4.5339, -5.6565, -4.8718, -4.7388, -6.5026, -7.6115, -7.5549,\n",
      "         -6.3509, -6.9961, -1.4404,  4.1583,  2.2680, -5.2259, -6.5947, -6.1802,\n",
      "         -2.3665,  1.1686, -3.4937, -6.4813, -3.8468,  0.1725, -5.5303, -6.3336,\n",
      "         -5.8032, -2.9688, -4.6860, -5.4696, -0.1818, -5.1853, -2.2407, -6.5513,\n",
      "         -7.1714, -3.8936, -1.9706, -6.5552, -6.8082, -5.2452, -7.3313, -5.2320,\n",
      "         -3.3209, -1.0072, -6.4820, -3.8524, -6.2275, -3.3956, -1.2329, -5.9539,\n",
      "         -1.7581, -7.1805, -5.7191, -3.0291, -4.2379,  7.1370,  4.5195, -4.0408,\n",
      "         -6.4917, -4.9578,  2.4371, -0.3887, -0.7629, -6.3811, -0.8037,  0.1397,\n",
      "         -5.5201, -6.4816, -7.1064, -5.5997, -7.0884, -3.8532, -7.2068, -2.6026,\n",
      "         -4.9569, -2.8674,  0.1073, -2.0707, -6.3507, -0.4962, -5.7243, -4.8729,\n",
      "          1.3792, -4.9203, -6.3533, -5.9925, -5.5069, -0.3561, -1.4737, -1.4404]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "print(output.start_logits, output.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(53) tensor(53)\n",
      "Text: \n",
      "Electric instruments such as the electric guitar, the electric bass and the ondes martenot appear occasionally in the classical music of the 20th and 21st centuries. both classical and popular musicians have experimented in recent decades with electronic instruments such as the synthesizer, electric and digital techniques such as the use of sampled or computer-generated sounds, and instruments from other cultures such as the gamelan.\n",
      "\n",
      "Question: \n",
      "What type of instrument is the gamelan?\n",
      "\n",
      "Answer: \n",
      "Electronic\n"
     ]
    }
   ],
   "source": [
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "print (answer_start, answer_end)\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end + 1])\n",
    "else:\n",
    "    print(\"I am unable to answer your question? Please pardon\")\n",
    "\n",
    "print(\"Text: \\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion: \\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer: \\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = tokens[answer_start]\n",
    "\n",
    "for i in range(answer_start+1, answer_end):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer +=tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "\n",
    "    # tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "\n",
    "    # string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # segment IDs\n",
    "    # first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # number of tokens in segment A - qustion \n",
    "    num_seg_a = sep_idx + 1\n",
    "\n",
    "    # number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # list of 0s and 1s\n",
    "    segment_ids =[0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # model output using input ids and sedment ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "\n",
    "    # reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
